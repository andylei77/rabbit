
- 无人驾驶简介
    - 感知:
        - 人:眼睛
        - 无人车：相机,毫米波,超声波,激光雷达
    - 定位：
        - 人：眼睛
        - 无人车：GPS IMU 相机 车轮里程计
    - 规划决策:
        - 人:大脑
        - 无人车： 规划算法
    - 执行：
        - 人:手 脚
        - 无人车： Can协议

- 为什么讲这个系列课程？
    - 总结所学
    - 一起做一个持续改进的项目


项目1-感知： Tensorflow实现目标检测
- Python版本检测车辆和行人
    -  搭建python版本tensorflow环境
    -  运行检测demo并做源码分析
    -  改写检测demo用于目标检测

- 根据python版本改写C++版本实现
    -  为什么需要C++版本？tensorflow是否可以用C++接口（tensorflow架构概述）?
    -  bazel编译tensorflow C++库、bazel基本介绍
    -  根据python接口编写C++版前向传播接口
    -  编译C++前向传播代码
    -  CMake工程实践经验
        - 核心idea（include link)

        - 三种书写方法揭露cmake最佳实践  （direct_include_link  find_package_include_link taget_include_link）
    -  第三方库管理杂谈  （用户自己装find/发布压缩包/子模块托管）

项目2-定位： ORB-SLAM2实现视觉定位

 - 搭建ORB-SLAM2运行环境并运行demo

- 使用ROS可视化定位效果

    - ROS环境安装 与 基本介绍

    - 创建ROS发图node和SLAM node

    - 使用ROS Rviz可视化定位效果
- ORB-SLAM2源码解析



项目3-整合：使用ROS整合检测与定位

- 创建目标检测node

- 实现检测与定位信息融合的基本架构

项目4-优化：优化感知

- 加入跟踪算法赋予ID信息(基于IoU的匹配/ 基于深度特征的匹配/基于跟踪算法的匹配 )

- 加入分割算法获取mask (mask后处理的源码分析及C++动手实现）

- 获取距离信息（图片预深度）

项目5-理论：理论补充
- 深度学习目标检测算法综述与源码分析
- 跟踪算法综述
- 分割算法综述

后续补充：
- 利用双目视觉进行深度估计
- 利用激光雷达信息优化感知
- 利用GPS和IMU数据优化定位